{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "wandb.login()\n",
    "wandb_project= 'label_round'\n",
    "wandb_run = wandb.init(project=wandb_project)\n",
    "wandb_run_id = wandb_run.id\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)#is using multi-GPU\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from classifier.load_data import LoadData\n",
    "from torch.utils.data import DataLoader\n",
    "from classifier.collote_data import collote_fn\n",
    "\n",
    "origin_data_pool = pd.read_csv('../dataset/datapool/data_pool.csv')\n",
    "data_pool = LoadData(path='../dataset/datapool/', data_type='data_pool')\n",
    "data_pool_dataloader = DataLoader(data_pool.data, batch_size=200, shuffle=True, collate_fn=collote_fn)\n",
    "train_data = LoadData(path='../dataset/pilotData/', data_type='train_data')\n",
    "train_dataloader = DataLoader(train_data, batch_size=20, shuffle=True, collate_fn=collote_fn)\n",
    "val_data = LoadData(path='../dataset/pilotData/', data_type='test_data')\n",
    "val_dataloader = DataLoader(val_data, batch_size=10, shuffle=True, collate_fn=collote_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AdamW, get_scheduler\n",
    "from classifier.multi_laber_classifier import classifer_model\n",
    "classifier = classifer_model()\n",
    "checkpoint=torch.load('learner/before_active_learning/checkpoint/model_weights.bin')\n",
    "learning_rate = 1e-5  # 学习率\n",
    "optimizer = AdamW(classifier.parameters(), lr=learning_rate) \n",
    "classifier.load_state_dict(checkpoint['estimator'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "start_epoch=checkpoint['epoch']\n",
    "completed_steps = start_epoch * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",  \n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=completed_steps,\n",
    ")\n",
    "lr_scheduler.load_state_dict(checkpoint['lr_schedule'])\n",
    "\n",
    "metrics={'best_error':3.36,'best_loss':0.12,'best_rank_pre':0.76,'best_avg_pre':0.53}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from learner.active_learner import MyActiveLearner\n",
    "from learner.query_strategy import min_confidence_sampling\n",
    "learner = MyActiveLearner(\n",
    "        estimator=classifier,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        query_strategy=min_confidence_sampling,\n",
    "        data_pool=data_pool_dataloader,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        metrics=metrics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "# Number of instances we want to annotate per iteration\n",
    "n_instances = 30\n",
    "query_idx, query_inst = learner.learner_query(n_instances=n_instances)#\n",
    "try:\n",
    "    probabilities = learner.predict(query_idx)#\n",
    "# For the very first query we do not have any predictions\n",
    "except NotFittedError:\n",
    "    probabilities = [[0.5]*10] * n_instances\n",
    "predict=[]\n",
    "for pred in probabilities:\n",
    "    for pre in pred:\n",
    "        temp=[]\n",
    "        for p in pre:\n",
    "            temp.append(float(p))\n",
    "        predict.append(temp)\n",
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import argilla as rg\n",
    "import datetime\n",
    "\n",
    "print(query_idx)\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900/\",\n",
    "    api_key=\"owner.apikey\",\n",
    "    # extra_headers={\"Authorization\": f\"Bearer {\"HF_TOKEN\"}\"}\n",
    ")\n",
    "label_list=[\"Achievement\",\"Self-direction\",\"Hedonism\", \"Security\", \"Power\", \"Stimulation\",\"Benevolence\", \"Universalism\",\"Conformity\",\"Tradition\"]\n",
    "inputs = []\n",
    "records=[]\n",
    "for i in query_idx:\n",
    "    print(i)\n",
    "    input = {}\n",
    "    sample_id=learner.data_pool.dataset[i]['id']#\n",
    "    sample_text_id=origin_data_pool['id'].tolist().index(sample_id)#\n",
    "    sample_text=origin_data_pool['text'][sample_text_id]#\n",
    "    input_text=str(sample_id)+':'+sample_text#\n",
    "    input['text']=input_text#\n",
    "    inputs.append(input)\n",
    "input_df=pd.Series(input for input in inputs)\n",
    "ids=[]\n",
    "for i in query_idx.tolist():\n",
    "    now_time = datetime.datetime.now()\n",
    "    temp_str=datetime.datetime.strftime(now_time,'%Y-%m-%d %H:%M:%S')\n",
    "    str_i=f'{i}'\n",
    "    id=str_i+'_'+temp_str\n",
    "    ids.append(id)\n",
    "for i in range(len(input_df)):\n",
    "    records.append(\n",
    "        rg.TextClassificationRecord(\n",
    "            id=ids[i],\n",
    "            inputs=input_df[i],\n",
    "            prediction=list(zip(label_list, predict[i])),\n",
    "            multi_label=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "settings = rg.TextClassificationSettings(label_schema=label_list)\n",
    "rg.log(workspace='admin',records=records,name=\"saner_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from learner.read_recore import get_labeldata_fromrubrix\n",
    "\n",
    "records_df = rg.load(\"saner_test\",ids=ids)#\n",
    "records_df = records_df.to_datasets()\n",
    "records_df = records_df.to_pandas()\n",
    "\n",
    "if any(records_df.annotation.isna()):\n",
    "    raise UserWarning(\"Please annotate first all your samples before teaching the model\")\n",
    "\n",
    "data_df=pd.DataFrame()\n",
    "\n",
    "data_df['label'] = records_df['annotation']\n",
    "\n",
    "id_list=[]\n",
    "text_list=[]\n",
    "\n",
    "data_list=list(data_pool.data.values())\n",
    "temp_id=[]\n",
    "temp_text=[]\n",
    "# temp_label=[]\n",
    "for data_dict in data_list:\n",
    "    temp_id.append(data_dict['id'])\n",
    "    temp_text.append(data_dict['text'])\n",
    "    # temp_label.append(data_dict['label'])\n",
    "\n",
    "for content in records_df['text']:\n",
    "    current=content.split(':',1)#\n",
    "    current_id=int(current[0])#\n",
    "    # current_text=current[1]#\n",
    "    current_text_id=temp_id.index(current_id)#\n",
    "    current_text=temp_text[current_text_id]#\n",
    "    id_list.append(current_id)\n",
    "    text_list.append(current_text)\n",
    "\n",
    "\n",
    "onehot_label_record=[]#\n",
    "for content in data_df['label'].tolist():\n",
    "    temp_label=get_labeldata_fromrubrix(content)\n",
    "    onehot_label_record.append(temp_label)\n",
    "\n",
    "addsample_train=[]\n",
    "for i in range(len(onehot_label_record)):\n",
    "    new_sample={}\n",
    "    new_sample['id']=id_list[i]\n",
    "\n",
    "    new_sample['text']=text_list[i]\n",
    "    # new_sample['text']=data_df['text'][i]\n",
    "    new_sample['label']=onehot_label_record[i]\n",
    "    addsample_train.append(new_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>epoch_more=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 # learner.my_teach(query_idx,addsample_train,epoch_more)#将新标注样本加入池子里，并重新 </span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 learner.my_teach_new(query_idx,addsample_train,start_epoch,epoch_more,wandb_project,wand     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\PycharmWorkspace\\ActiveLearningForHumanValue\\learner\\active_learner.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">235</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">my_teach_new</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">232 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>end_epoch = start_epoch + epoch_num                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">233 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#更新训练池</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">234 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>train_dict_dataset = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.train_dataloader.dataset                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>235 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>train_dict=train_dict_dataset.data                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">236 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>lenth=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(train_dict.keys())                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">237 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(lenth)                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># 计算断点处已经完成的总的训练步数</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'dict'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mepoch_more=\u001b[94m5\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m# learner.my_teach(query_idx,addsample_train,epoch_more)#将新标注样本加入池子里，并重新 \u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 learner.my_teach_new(query_idx,addsample_train,start_epoch,epoch_more,wandb_project,wand     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mD:\\PycharmWorkspace\\ActiveLearningForHumanValue\\learner\\active_learner.py\u001b[0m:\u001b[94m235\u001b[0m in \u001b[92mmy_teach_new\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m232 \u001b[0m\u001b[2m│   │   \u001b[0mend_epoch = start_epoch + epoch_num                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m233 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m#更新训练池\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m234 \u001b[0m\u001b[2m│   │   \u001b[0mtrain_dict_dataset = \u001b[96mself\u001b[0m.train_dataloader.dataset                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m235 \u001b[2m│   │   \u001b[0mtrain_dict=train_dict_dataset.data                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m236 \u001b[0m\u001b[2m│   │   \u001b[0mlenth=\u001b[96mlen\u001b[0m(train_dict.keys())                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m237 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(lenth)                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m238 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 计算断点处已经完成的总的训练步数\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'dict'\u001b[0m object has no attribute \u001b[32m'data'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_more=50\n",
    "learner.my_teach_new(query_idx,addsample_train,start_epoch,epoch_more,wandb_project,wandb_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/label_round/label_epoch/2024_10_10_16_33_27/rubrix/train_rubrix.csv\n",
      "data stored\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "from getLabelReview import get_data_fromrubrix\n",
    "import datetime\n",
    "\n",
    "now_time = datetime.datetime.now()\n",
    "temp_str = datetime.datetime.strftime(now_time, '%Y-%m-%d %H:%M:%S')\n",
    "strs = re.sub(r\"\"\"[-|:| ]\"\"\", \"_\", temp_str)\n",
    "base_path = f'dataset/label_round/label_epoch/'\n",
    "temp_path = base_path + strs#\n",
    "rubrix_path=temp_path+'/rubrix'\n",
    "train_path=temp_path+'/train'\n",
    "os.makedirs(rubrix_path)\n",
    "os.makedirs(train_path)\n",
    "currentTrainPathBase=rubrix_path+'/train_rubrix.csv'\n",
    "currentTrainFilePath=train_path+'/current_train.csv'\n",
    "print(currentTrainPathBase)\n",
    "get_data_fromrubrix('saner_test',currentTrainPathBase,currentTrainFilePath,agentName=None)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from classifier.data_preprocess import data_preprocess_first, data_preprocess_sencond\n",
    "\n",
    "from dataset.dataConcat import concatCSV\n",
    "\n",
    "add_train_path1=train_path+'/current_train_after1.csv'\n",
    "add_train_path2=train_path+'/current_train_after2.csv'\n",
    "\n",
    "data_preprocess_first(currentTrainFilePath,add_train_path1)#\n",
    "data_preprocess_sencond(add_train_path1,add_train_path2)#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_base='../dataset/pilotData/train_data.csv'#\n",
    "train_data_path=train_path+'/current_train_added.csv'#\n",
    "concatCSV(train_base,add_train_path2,train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from test_train import testtrain\n",
    "testtrain(learner.estimator,learner.train_dataloader,learner.val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
